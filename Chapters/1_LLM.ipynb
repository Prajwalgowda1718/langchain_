{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e64086a",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da6fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_gemini\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv                                  #for loading environment variables\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI       #for google genai | llm\n",
    "from langchain_core.prompts import ChatPromptTemplate           #for prompt template | prompt\n",
    "from langchain.agents import initialize_agent, AgentType        \n",
    "from langchain.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser       #for output parser\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ae577",
   "metadata": {},
   "source": [
    "### Simple Example |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c474219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:27: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully\n",
      "✅ LLM connection successful!\n",
      "Response: The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is loaded\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # this function reads the GOOGLE_API_KEY from the environment variables\n",
    "if not api_key:\n",
    "    print(\"❌ GOOGLE_API_KEY not found. Check your .env file.\")\n",
    "    exit(1) # exit(1) function is used to terminate the program with a non-zero status, indicating an error.\n",
    "\n",
    "print(\"✅ API key loaded successfully\")\n",
    "\n",
    "# Test a simple LLM call using Gemini\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "    response = llm.invoke(\"what is the capital of France?\")\n",
    "    print(f\"✅ LLM connection successful!\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5869e2",
   "metadata": {},
   "source": [
    "##### My code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8917c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to call LLm\n",
      "\n",
      " Task completed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"no Api key\")\n",
    "    exit(\"NO APi key found\")\n",
    "\n",
    "try:\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.6)\n",
    "    response_1=llm.invoke(\"which is city is called silk city in karnataka india ?\")\n",
    "    print(\"LLm connection sucsseful\")\n",
    "    print(f\" \\n{response_1.content} \")\n",
    "except:\n",
    "    print(\"unable to call LLm\")\n",
    "\n",
    "finally:\n",
    "    print(\"\\n Task completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b7b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city called **Mandya** is known as the \"Sugar City\" in Karnataka, India.\n",
      "\n",
      "This is because of its extensive sugarcane cultivation and numerous sugar mills.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{response_1.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf72a65",
   "metadata": {},
   "source": [
    "### Without LangChain (raw API call) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b5c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 largest countries in the world by total area are:\n",
      "\n",
      "1.  **Russia** (approx. 17.1 million square kilometers)\n",
      "2.  **Canada** (approx. 9.98 million square kilometers)\n",
      "3.  **China** (approx. 9.6 million square kilometers)\n",
      "4.  **United States** (approx. 9.8 million square kilometers - *Note: The exact ranking between China and the United States can vary slightly depending on whether territorial waters are included and the specific measurement methodologies.*)\n",
      "5.  **Brazil** (approx. 8.5 million square kilometers)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model=genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "response=model.generate_content(\"what are the top 5 largest countries in the world\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a39b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of India is **Droupadi Murmu**.\n",
      "\n",
      "She assumed office on July 25, 2022, and is the 15th President of India. She is also the first tribal person and the second woman to hold the office.\n"
     ]
    }
   ],
   "source": [
    "res=model.generate_content(\"who is the president of india ?\").text\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82937a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mres\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{res}\")\n",
    "#the response will be json format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b121",
   "metadata": {},
   "source": [
    "### With LangChain |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5abc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - 2 = 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create reusable LLM object\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3 )\n",
    "\n",
    "# Simple call\n",
    "response = llm.invoke(\"What is 2-2?\")\n",
    "print(response.content)\n",
    "\n",
    "# Easy to add prompts, chains, memory, tools later!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497843f8",
   "metadata": {},
   "source": [
    " Change the temperature (try 0.0, 0.5, 1.0) and ask the same question. Notice how responses change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9cdd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.0\n",
      " Response:No, dragons are mythical creatures, and dinosaurs were real animals that lived millions of years ago.\n",
      "\n",
      " 1 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.3\n",
      " Response:No, dragons are mythical creatures and dinosaurs were real animals that lived millions of years ago.\n",
      "\n",
      " 2 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.5\n",
      " Response:No, dinosaurs were real animals that lived millions of years ago, while dragons are mythical creatures.\n",
      "\n",
      " 3 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.7\n",
      " Response:No, dinosaurs were real prehistoric animals, and dragons are mythical creatures.\n",
      "\n",
      " 4 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 1\n",
      " Response:No, dinosaurs were real animals that lived millions of years ago, while dragons are mythical creatures.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for i, temp in enumerate([0.0,0.3,0.5,0.7,1]):\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=temp)\n",
    "    response=llm.invoke(\"did dragon and dinosaur live together? give me one line answer\")\n",
    "    print(f\"\\n {i} Promt: did dragon and dinosaur live together? give me one line answer \\n Temperatire: {temp}\\n Response:{response.content}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9577e",
   "metadata": {},
   "source": [
    "### LangChain Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad7259",
   "metadata": {},
   "source": [
    "#### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ce4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Vladimir Putin** is currently the President of Russia.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.8)\n",
    "\n",
    "response=gemini.invoke(\"who is president of russia\")\n",
    "print(f\"{response.text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519c7e0",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI (if you have an API key)\n",
    "openai= ChatOpenAI(model=\"GPT-4.0\",temperature=1.0)\n",
    "\n",
    "# If you had OpenAI configured:\n",
    "response = openai.invoke(\"Explain quantum computing in one sentence.\")\n",
    "print(f\"OpenAI: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f547213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "**\"You are stronger than you think. Take that first step, even if it's small, and watch how far you can go.\"**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=gemini.invoke(\"write a motivational quote\")\n",
    "print(f\"{response.content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
